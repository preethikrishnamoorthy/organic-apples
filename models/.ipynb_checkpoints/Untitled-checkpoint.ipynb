{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d09cd80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import regex as re\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91431918",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_website_text</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>official site good hotel accommodation big sav...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>expedia hotel book sites like use vacation wor...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tripadvisor hotel book sites like previously d...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cheap flights search compare flights momondo f...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bot create free account create free account si...</td>\n",
       "      <td>Travel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1403</th>\n",
       "      <td>old nude women porn mature granny sex horny ol...</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>bdsm cams bdsm chat bondage cams free bdsm vid...</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>porno dvd online european porn dvd cheap adult...</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>anal dream house anal dream house anal dream h...</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>world sex news daily sex news adult news eroti...</td>\n",
       "      <td>Adult</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1408 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   cleaned_website_text Category\n",
       "0     official site good hotel accommodation big sav...   Travel\n",
       "1     expedia hotel book sites like use vacation wor...   Travel\n",
       "2     tripadvisor hotel book sites like previously d...   Travel\n",
       "3     cheap flights search compare flights momondo f...   Travel\n",
       "4     bot create free account create free account si...   Travel\n",
       "...                                                 ...      ...\n",
       "1403  old nude women porn mature granny sex horny ol...    Adult\n",
       "1404  bdsm cams bdsm chat bondage cams free bdsm vid...    Adult\n",
       "1405  porno dvd online european porn dvd cheap adult...    Adult\n",
       "1406  anal dream house anal dream house anal dream h...    Adult\n",
       "1407  world sex news daily sex news adult news eroti...    Adult\n",
       "\n",
       "[1408 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"website_classification.csv\")\n",
    "df = (data [[\"cleaned_website_text\", \"Category\"]]).dropna(axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3531d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    sentence = remove_tags(sen)\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    return sentence\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9987cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "sentences = list(df[\"cleaned_website_text\"])\n",
    "for sen in sentences:\n",
    "    X.append(preprocess_text(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c29f7c85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 3, 3, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process (x):\n",
    "    if x ==\"Travel\": return 1\n",
    "    elif x==\"Social Networking and Messaging\": return 2\n",
    "    elif \"News\": return 3\n",
    "    elif \"Streaming Services\": return 4\n",
    "    elif \"Sports\": return 5\n",
    "    elif \"Photography\": return 6\n",
    "    elif \"Law and Government\": return 7\n",
    "    elif \"Health and Fitness\": return 8\n",
    "    elif \"Games\": return 9\n",
    "    elif \"Forums\": return 10\n",
    "    elif \"Food\": return 11\n",
    "    elif \"Education\": return 12\n",
    "    elif \"E-Commerce\": return 13\n",
    "    elif \"Computers and Technology\": return 14\n",
    "    elif \"Business/Corporate\": return 15\n",
    "    else: return 0\n",
    "\n",
    "\n",
    "y = np.array(list(map(process, df[\"Category\"])))\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bafe927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dadd9678",
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyper parameters\n",
    "batch_size = 32\n",
    "embedding_dims = 75 #Length of the token vectors\n",
    "filters = 250 #number of filters in your Convnet\n",
    "kernel_size = 3 # a window size of 3 tokens\n",
    "hidden_dims = 250 #number of neurons at the normal feedforward NN\n",
    "epochs = 2\n",
    "maxlen=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6481f967",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(Conv1D(filters,kernel_size,padding = 'valid' , activation = 'relu',strides = 1 ))\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "#GlobalMaxPooling1D(n) default = 2.\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51aaabcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "36/36 [==============================] - 1s 10ms/step - loss: -30506.8926 - accuracy: 0.0737 - val_loss: -79580.4688 - val_accuracy: 0.0674\n",
      "Epoch 2/2\n",
      "36/36 [==============================] - 0s 3ms/step - loss: -163863.6406 - accuracy: 0.0782 - val_loss: -266583.2500 - val_accuracy: 0.0674\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d90f316700>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy',optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(X_train,y_train,batch_size = batch_size,epochs = epochs , validation_data = (X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86994131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0673758865248227"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = np.array(list(map(lambda x : int(x[0]), pred)))\n",
    "accuracy = accuracy_score(pred,y_test)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be01062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
