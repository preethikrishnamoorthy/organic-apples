{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d09cd80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import regex as re\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import GlobalMaxPooling1D, Conv1D\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91431918",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Tweets.csv\")\n",
    "df = (data [[\"textID\", \"text\", \"sentiment\"]]).dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3531d24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(sen):\n",
    "    sentence = remove_tags(sen)\n",
    "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
    "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
    "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
    "    return sentence\n",
    "\n",
    "TAG_RE = re.compile(r'<[^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub('', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9987cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "sentences = list(df[\"text\"])\n",
    "for sen in sentences:\n",
    "    X.append(preprocess_text(sen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c29f7c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process (x):\n",
    "    if x ==\"positive\": return 1\n",
    "    elif x==\"negative\": return -1\n",
    "    else: return 0\n",
    "\n",
    "\n",
    "X = df[\"text\"]\n",
    "y = np.array(list(map(process, df[\"sentiment\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bafe927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Adding 1 because of reserved 0 index\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "maxlen = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dadd9678",
   "metadata": {},
   "outputs": [],
   "source": [
    "##hyper parameters\n",
    "batch_size = 32\n",
    "embedding_dims = 75 #Length of the token vectors\n",
    "filters = 250 #number of filters in your Convnet\n",
    "kernel_size = 3 # a window size of 3 tokens\n",
    "hidden_dims = 250 #number of neurons at the normal feedforward NN\n",
    "epochs = 2\n",
    "maxlen=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6481f967",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# model.add(Conv1D(filters,kernel_size,padding = 'valid' , activation = 'relu',strides = 1 ))\n",
    "# model.add(GlobalMaxPooling1D())\n",
    "#GlobalMaxPooling1D(n) default = 2.\n",
    "model.add(Dense(hidden_dims))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51aaabcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "687/687 [==============================] - 1s 1ms/step - loss: 6.7997 - accuracy: 0.4012 - val_loss: -0.3264 - val_accuracy: 0.4056\n",
      "Epoch 2/2\n",
      "687/687 [==============================] - 1s 1ms/step - loss: -6.6783 - accuracy: 0.4008 - val_loss: 0.3631 - val_accuracy: 0.4067\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2e9ece7b4f0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss = 'binary_crossentropy',optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.fit(X_train,y_train,batch_size = batch_size,epochs = epochs , validation_data = (X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3e2fcf95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172/172 [==============================] - 0s 526us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.40756914119359533"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = np.array(list(map(lambda x : int(x[0]), pred)))\n",
    "accuracy = accuracy_score(pred,y_test)\n",
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "b66052156ab8f78f561de088d9fbc54bdecac7e8014a9ce2aa7fb5f353827e4a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
